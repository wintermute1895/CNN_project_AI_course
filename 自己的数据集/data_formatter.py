import cv2
import numpy as np
import os
import random
from PIL import Image, ImageEnhance
import xml.etree.ElementTree as ET
import math

def cv_imread(file_path):
    """æ”¯æŒä¸­æ–‡è·¯å¾„çš„OpenCVå›¾åƒè¯»å–å‡½æ•°"""
    img_data = np.fromfile(file_path, dtype=np.uint8)
    img = cv2.imdecode(img_data, cv2.IMREAD_COLOR)
    return img

def cv_imwrite(file_path, image):
    """æ”¯æŒä¸­æ–‡è·¯å¾„çš„OpenCVå›¾åƒä¿å­˜å‡½æ•°"""
    ext = os.path.splitext(file_path)[1]
    success, encoded_image = cv2.imencode(ext, image)
    if success:
        with open(file_path, 'wb') as f:
            f.write(encoded_image)
    return success

def rotate_image_and_bbox(image, bboxes, angle):
    """
    æ—‹è½¬å›¾åƒå’Œè¾¹ç•Œæ¡†
    :param image: è¾“å…¥å›¾åƒ (OpenCVæ ¼å¼)
    :param bboxes: YOLOæ ¼å¼è¾¹ç•Œæ¡†åˆ—è¡¨ [[class_id, x_center, y_center, width, height], ...]
    :param angle: æ—‹è½¬è§’åº¦ï¼ˆåº¦ï¼‰
    :return: æ—‹è½¬åçš„å›¾åƒå’Œè¾¹ç•Œæ¡†
    """
    img_h, img_w = image.shape[:2]  # é‡å‘½åé¿å…å˜é‡å†²çª
    center = (img_w // 2, img_h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])
    
    # è®¡ç®—æ–°å›¾åƒå°ºå¯¸
    nW = int((img_h * sin) + (img_w * cos))
    nH = int((img_h * cos) + (img_w * sin))
    M[0, 2] += (nW / 2) - center[0]
    M[1, 2] += (nH / 2) - center[1]
    
    # æ—‹è½¬å›¾åƒ
    rotated = cv2.warpAffine(image, M, (nW, nH), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    
    # æ—‹è½¬è¾¹ç•Œæ¡†ï¼ˆä¿®å¤åæ ‡è½¬æ¢é”™è¯¯ï¼‰
    rotated_bboxes = []
    for bbox in bboxes:
        class_id, x, y, w, h = bbox
        
        # è½¬æ¢ä¸ºç»å¯¹åæ ‡ï¼ˆä½¿ç”¨å›¾åƒå°ºå¯¸ï¼Œè€Œéè¾¹ç•Œæ¡†å°ºå¯¸ï¼‰
        abs_x = x * img_w
        abs_y = y * img_h
        abs_w = w * img_w
        abs_h = h * img_h
        
        # è®¡ç®—è¾¹ç•Œæ¡†å››ä¸ªè§’ç‚¹
        points = np.array([
            [abs_x - abs_w/2, abs_y - abs_h/2],
            [abs_x + abs_w/2, abs_y - abs_h/2],
            [abs_x + abs_w/2, abs_y + abs_h/2],
            [abs_x - abs_w/2, abs_y + abs_h/2]
        ])
        
        # åº”ç”¨æ—‹è½¬çŸ©é˜µ
        ones = np.ones(shape=(len(points), 1))
        points_ones = np.hstack([points, ones])
        transformed_points = M.dot(points_ones.T).T
        
        # è®¡ç®—æ–°è¾¹ç•Œæ¡†
        min_x, min_y = np.min(transformed_points, axis=0)
        max_x, max_y = np.max(transformed_points, axis=0)
        
        # è½¬æ¢ä¸ºYOLOæ ¼å¼
        new_x = ((min_x + max_x) / 2) / nW
        new_y = ((min_y + max_y) / 2) / nH
        new_w = (max_x - min_x) / nW
        new_h = (max_y - min_y) / nH
        
        # ç¡®ä¿è¾¹ç•Œæ¡†åœ¨å›¾åƒå†…ä¸”å¤§å°åˆç†
        if (0 <= new_x <= 1 and 0 <= new_y <= 1 and 
            0.01 <= new_w <= 0.99 and 0.01 <= new_h <= 0.99):
            rotated_bboxes.append([class_id, new_x, new_y, new_w, new_h])
    
    return rotated, rotated_bboxes

def adjust_exposure(image, factor):
    """
    è°ƒæ•´å›¾åƒæ›å…‰åº¦
    :param image: è¾“å…¥å›¾åƒ (OpenCVæ ¼å¼)
    :param factor: æ›å…‰è°ƒæ•´å› å­ (0.5=å˜æš—, 1.0=ä¸å˜, 2.0=å˜äº®)
    :return: è°ƒæ•´åçš„å›¾åƒ
    """
    # ä½¿ç”¨PILè¿›è¡Œæ›´è‡ªç„¶çš„æ›å…‰è°ƒæ•´
    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    enhancer = ImageEnhance.Brightness(pil_img)
    adjusted = enhancer.enhance(factor)
    return cv2.cvtColor(np.array(adjusted), cv2.COLOR_RGB2BGR)

def adjust_hue(image, factor):
    """
    è°ƒæ•´å›¾åƒè‰²è°ƒ
    :param image: è¾“å…¥å›¾åƒ (OpenCVæ ¼å¼)
    :param factor: è‰²è°ƒè°ƒæ•´å› å­ (-1.0åˆ°1.0)
    :return: è°ƒæ•´åçš„å›¾åƒ
    """
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    hsv = hsv.astype(np.float32)
    hsv[:, :, 0] = (hsv[:, :, 0] + factor * 180) % 180
    hsv = np.clip(hsv, 0, 255).astype(np.uint8)
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

def random_crop(image, bboxes, min_scale=0.6, max_scale=0.9):
    """
    éšæœºè£åˆ‡å›¾åƒå¹¶è°ƒæ•´è¾¹ç•Œæ¡†
    :param image: è¾“å…¥å›¾åƒ
    :param bboxes: YOLOæ ¼å¼è¾¹ç•Œæ¡†åˆ—è¡¨
    :param min_scale: æœ€å°è£åˆ‡æ¯”ä¾‹
    :param max_scale: æœ€å¤§è£åˆ‡æ¯”ä¾‹
    :return: è£åˆ‡åçš„å›¾åƒå’Œè¾¹ç•Œæ¡†
    """
    h, w = image.shape[:2]
    scale = random.uniform(min_scale, max_scale)
    new_w, new_h = int(w * scale), int(h * scale)
    
    # éšæœºé€‰æ‹©è£åˆ‡èµ·ç‚¹
    x = random.randint(0, w - new_w)
    y = random.randint(0, h - new_h)
    
    # è£åˆ‡å›¾åƒ
    cropped = image[y:y+new_h, x:x+new_w]
    
    # è°ƒæ•´è¾¹ç•Œæ¡†ï¼ˆä¿®å¤åæ ‡è½¬æ¢é”™è¯¯ï¼‰
    cropped_bboxes = []
    for bbox in bboxes:
        class_id, bx, by, bw, bh = bbox
        
        # è½¬æ¢ä¸ºç»å¯¹åæ ‡ï¼ˆä½¿ç”¨å›¾åƒå°ºå¯¸ï¼‰
        abs_x = bx * w
        abs_y = by * h
        abs_w = bw * w
        abs_h = bh * h
        
        # è®¡ç®—è¾¹ç•Œæ¡†åœ¨æ–°å›¾åƒä¸­çš„ä½ç½®
        new_x = (abs_x - x) / new_w
        new_y = (abs_y - y) / new_h
        new_w_val = abs_w / new_w
        new_h_val = abs_h / new_h
        
        # æ£€æŸ¥è¾¹ç•Œæ¡†æ˜¯å¦åœ¨è£åˆ‡åŒºåŸŸå†…
        if (0 <= new_x <= 1 and 0 <= new_y <= 1 and 
            new_x - new_w_val/2 >= 0 and new_x + new_w_val/2 <= 1 and
            new_y - new_h_val/2 >= 0 and new_y + new_h_val/2 <= 1):
            cropped_bboxes.append([class_id, new_x, new_y, new_w_val, new_h_val])
    
    return cropped, cropped_bboxes

def read_yolo_annotation(annotation_path):
    """
    è¯»å–YOLOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶
    :param annotation_path: æ ‡æ³¨æ–‡ä»¶è·¯å¾„
    :return: è¾¹ç•Œæ¡†åˆ—è¡¨ [[class_id, x_center, y_center, width, height], ...]
    """
    bboxes = []
    if not os.path.exists(annotation_path):
        print(f"âš ï¸ æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {annotation_path}")
        return bboxes
        
    with open(annotation_path, 'r', encoding='utf-8') as f:
        for line in f.readlines():
            data = line.strip().split()
            if len(data) == 5:
                try:
                    class_id = int(data[0])
                    x_center = float(data[1])
                    y_center = float(data[2])
                    width = float(data[3])
                    height = float(data[4])
                    bboxes.append([class_id, x_center, y_center, width, height])
                except ValueError:
                    print(f"âš ï¸ æ ‡æ³¨æ ¼å¼é”™è¯¯: {line.strip()}")
    return bboxes

def write_yolo_annotation(annotation_path, bboxes):
    """
    å†™å…¥YOLOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶
    :param annotation_path: è¾“å‡ºæ ‡æ³¨æ–‡ä»¶è·¯å¾„
    :param bboxes: è¾¹ç•Œæ¡†åˆ—è¡¨
    """
    with open(annotation_path, 'w', encoding='utf-8') as f:
        for bbox in bboxes:
            line = f"{bbox[0]} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f} {bbox[4]:.6f}\n"
            f.write(line)

def process_dataset(input_dir, output_dir, operations):
    """
    å¤„ç†æ•´ä¸ªæ•°æ®é›†ï¼ˆæ·»åŠ ä¸­æ–‡è·¯å¾„æ”¯æŒï¼‰
    :param input_dir: è¾“å…¥æ•°æ®é›†ç›®å½•
    :param output_dir: è¾“å‡ºæ•°æ®é›†ç›®å½•
    :param operations: è¦åº”ç”¨çš„æ“ä½œåˆ—è¡¨
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆæ·»åŠ exist_oké¿å…é”™è¯¯ï¼‰
    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'labels'), exist_ok=True)
    
    # éå†æ‰€æœ‰å›¾åƒæ–‡ä»¶ï¼ˆæ·»åŠ è·¯å¾„éªŒè¯ï¼‰
    image_dir = os.path.join(input_dir, 'images')
    label_dir = os.path.join(input_dir, 'labels')
    
    if not os.path.exists(image_dir):
        print(f"âŒ å›¾åƒç›®å½•ä¸å­˜åœ¨: {image_dir}")
        return
    if not os.path.exists(label_dir):
        print(f"âŒ æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨: {label_dir}")
        return
    
    processed_count = 0
    for image_name in os.listdir(image_dir):
        if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):
            image_path = os.path.join(image_dir, image_name)
            base_name = os.path.splitext(image_name)[0]
            label_path = os.path.join(label_dir, base_name + '.txt')
            
            # ä½¿ç”¨æ”¯æŒä¸­æ–‡è·¯å¾„çš„è¯»å–æ–¹æ³•
            image = cv_imread(image_path)
            if image is None:
                print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
                continue
                
            # æ·»åŠ æ ‡æ³¨æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
            if not os.path.exists(label_path):
                print(f"âš ï¸ æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {label_path}")
                continue
                
            bboxes = read_yolo_annotation(label_path)
            if not bboxes:
                print(f"âš ï¸ æ— æœ‰æ•ˆæ ‡æ³¨: {label_path}")
                continue
                
            # åº”ç”¨æ‰€æœ‰æ“ä½œ
            processed_image = image.copy()
            processed_bboxes = [bbox.copy() for bbox in bboxes]
            
            for operation in operations:
                try:
                    if operation == 'rotate':
                        angle = random.uniform(-30, 30)
                        processed_image, processed_bboxes = rotate_image_and_bbox(
                            processed_image, processed_bboxes, angle)
                    
                    elif operation == 'exposure':
                        factor = random.uniform(0.7, 1.3)
                        processed_image = adjust_exposure(processed_image, factor)
                    
                    elif operation == 'hue':
                        factor = random.uniform(-0.1, 0.1)
                        processed_image = adjust_hue(processed_image, factor)
                    
                    elif operation == 'crop':
                        processed_image, processed_bboxes = random_crop(
                            processed_image, processed_bboxes)
                except Exception as e:
                    print(f"âš ï¸ æ“ä½œ {operation} å¤±è´¥: {e}")
                    continue
            
            # ä¿å­˜å¤„ç†åçš„å›¾åƒå’Œæ ‡æ³¨
            output_image_path = os.path.join(output_dir, 'images', image_name)
            output_label_path = os.path.join(output_dir, 'labels', base_name + '.txt')
            
            # ä½¿ç”¨æ”¯æŒä¸­æ–‡è·¯å¾„çš„ä¿å­˜æ–¹æ³•
            if not cv_imwrite(output_image_path, processed_image):
                print(f"âŒ å›¾åƒä¿å­˜å¤±è´¥: {output_image_path}")
            write_yolo_annotation(output_label_path, processed_bboxes)
            
            processed_count += 1
            if processed_count % 10 == 0:
                print(f"âœ… å·²å¤„ç† {processed_count} å¼ å›¾åƒ")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # é…ç½®å‚æ•°ï¼ˆä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²é¿å…è½¬ä¹‰é—®é¢˜ï¼‰
    INPUT_DATASET = r"E:\vs doc\change\è‡ªå·±çš„æ•°æ®é›†"  # è¾“å…¥æ•°æ®é›†è·¯å¾„
    OUTPUT_DATASET = r"E:\vs doc\change\è¾“å‡ºæ•°æ®é›†"  # è¾“å‡ºæ•°æ®é›†è·¯å¾„
    OPERATIONS = ['rotate', 'exposure', 'hue']  # è¦åº”ç”¨çš„æ“ä½œ'rotate', 'exposure', 'hue', 'crop'
    
    # å¤„ç†æ•°æ®é›†ï¼ˆæ·»åŠ å¼‚å¸¸æ•è·ï¼‰
    try:
        print("ğŸš€ å¼€å§‹å¤„ç†æ•°æ®é›†...")
        process_dataset(
            input_dir=INPUT_DATASET,
            output_dir=OUTPUT_DATASET,
            operations=OPERATIONS
        )
        print("âœ… æ•°æ®é›†å¤„ç†å®Œæˆ")
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")